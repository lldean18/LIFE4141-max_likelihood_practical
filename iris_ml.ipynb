{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12d2ad37-f864-41e1-a61c-88e72acc1b75",
   "metadata": {},
   "source": [
    "# Analyzing the Iris Dataset\n",
    "\n",
    "#### In this analysis, you will use two machine learning methods implemented in python to predict the species of Iris based on its flower anatomy.\n",
    "\n",
    "#### Please take your time with this analysis. Run each command (using Shift + Enter) and think about what you are asking the computer to do.\n",
    "\n",
    "#### The iris dataset was compiled by [R. A. Fisher](https://en.wikipedia.org/wiki/Ronald_Fisher) and published in 1936, which is ages ago. Though initially used for fairly naive discrimination methods, it is an early example of machine learning for predictive data in biology. You can read more about the dataset on [Wikipedia](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n",
    "\n",
    "#### The first thing we will do is load the data, which is included as part of the sklearn python module. If you end up using machine learning in your practcal projects, it is likely that sklearn will be of use to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e320a8-bc44-48cb-9ae3-0419a2fb398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_dataset = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6555c4-5a49-4b48-a3a4-5d85407a0281",
   "metadata": {},
   "source": [
    "#### We can quickly check a few things to ensure our data are loaded.\n",
    "\n",
    "> #### 1. The data type - in python, we tend to call the data type used by sklearn a [\"Bunch\"](https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch)\n",
    "> #### 2. The column headers (keys)\n",
    "> #### 3. The values of the first 5 rows of data\n",
    "> #### 4. The species each row's data belong to\n",
    "> #### 5. The names of those species\n",
    "> #### 6. The feature (variable) names\n",
    "> #### 7. The location of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5938448d-961d-4323-9efc-d2d24a31ea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(iris_dataset)\n",
    "print(\"Keys of iris_dataset: \\n{}\".format(iris_dataset.keys()))\n",
    "print(\"\\n\")\n",
    "print(\"First five columns of data:\\n{}\".format(iris_dataset['data'][:5]))\n",
    "print(\"\\n\")\n",
    "print(\"Targets:\\n{}\".format(iris_dataset['target'][:]))\n",
    "print(\"\\n\")\n",
    "print(\"Target names:\\n{}\".format(iris_dataset['target_names']))\n",
    "print(\"\\n\")\n",
    "print(\"Feature names:\\n{}\".format(iris_dataset['feature_names']))\n",
    "print(\"\\n\")\n",
    "print(\"Dataset location:\\n{}\".format(iris_dataset['filename']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3601092f-e442-49ae-8166-e5261a88263b",
   "metadata": {},
   "source": [
    "#### We can also look at the description of the dataset provided by one of the hardworking folks at sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775790e6-b497-499a-8f48-f92098c1b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris_dataset['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee96216-b930-4be6-89a7-f089c3a21b96",
   "metadata": {},
   "source": [
    "\n",
    "#### OK - we can be fairly confident that our data are loaded correctly.\n",
    "\n",
    "#### Now we need to set our data up for analysis. We are using the handy python function \"train_test_split\" from the sklearn module. This converts our data into a test set and a training set. Have a look at how the funciton is implemented here and consider the arguments. random_state is set to 0 - don't worry about this. It's just the random seed and by fixing it we guarentee that we all get the same result. Normally, this would not be set.\n",
    "\n",
    "\n",
    "### Questions\n",
    ">#### 1. Why do we split our dataset into a training set and a test set?\n",
    ">#### 2. What proportion of the dataset will be included in the training set?\n",
    ">#### 3. Given our use of train_test_split, do you think the algorithms we will be using are supervised, or unsupervised method?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fc3cb7-96d4-47c5-bb85-fa3b10bb8dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        iris_dataset['data'], iris_dataset['target'], test_size=0.25, random_state=0)\n",
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"X_test shape: {}\".format(X_test.shape)) \n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f58765b-e69d-4c55-a966-fb5dcd01e5b9",
   "metadata": {},
   "source": [
    "#### The output of the above tells you the dimentions of the data - what it's saying is that, for example, the training dataset is 112 plants with 4 features plus the Y variable (species)\n",
    "\n",
    "#### Now we will convert the data into a [\"pandas\"](https://pandas.pydata.org/docs/user_guide/index.html) dataframe. As far as I'm aware, pandas has nothing to do with the [black and white balls of clumsyness that they have in Edinburgh zoo](https://www.wwf.org.uk/learn/fascinating-facts/pandas). More boringly, it is a set of functions that allow us to interpret python data in data-frames, like you might be used to in R. A lot of sklearn functions rely on pandas data structures.\n",
    "\n",
    "#### We can then plot the 4 measurement variables against each other, observing how they correlate and how species tend to cluster with each other. We call this a [scatter matrix](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.plotting.scatter_matrix.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de8ee85-b2cc-4cba-8352-83e81b9b8cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "iris_dataframe = pd.DataFrame(X_train, columns=iris_dataset.feature_names)\n",
    "grr = pd.plotting.scatter_matrix(iris_dataframe, c=y_train, figsize=(15, 15), marker='o',hist_kwds={'bins': 20}, s=60, alpha=.8)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow([np.unique(iris_dataset.target)])\n",
    "_ = plt.xticks(ticks=np.unique(iris_dataset.target),labels=iris_dataset.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81125ed5-97a5-4d8b-a43e-40adf68b79c2",
   "metadata": {},
   "source": [
    "### Questions\n",
    ">#### 4. Given the scatter matrix above, which combination of features will be most likely to create an accurate model with which to predict the species of iris?\n",
    ">#### 5. Given the scatter matrix above, which species will be the easiest to predict?\n",
    "\n",
    "#### Right. Now you get to do some actual computation. We will be implementing the [K Neighbours](https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification) algorithm to create a model to predict the species of iris from petal length and petal width, which you hopefully identified as the most informative pair of features above. K Neighbours is a very simple method whose model is built simply by asking for a datapoint, the identify of the nearest K neighbours. The majority vote amounts to the prediction for that point. There is one parameter - n_neighbors (K). This is the size of the sample of nearest neighbours to make a prediction from. i.e. K=1 - the prediction is the identity of the nearest neighbour. K=3 - the prediction is the identity of the highest number of the nearest 3 neighbours. In our case, we will set this to one. Have a think about how changing this might affect your predictions.\n",
    "\n",
    "#### Technically, unless we are estimating K, which we are not here, K nearest neighbours is not machine learning, but a lot of the principles that we learned in the lecture apply.\n",
    "\n",
    "#### The way that sklearn works is, to my mind, a bit unintuitive. First, you create a variable that features all of the hyperparameters with which you can make your model (here that variable is knn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e156fd3b-1cbf-4abb-8ca5-30d257d72b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ac8225-418b-46d1-8e46-2b59ee361750",
   "metadata": {},
   "source": [
    "#### Then you can fit the model on the data - we have here chosen to fit it to the petal length and petal width `(X_train[:,2:])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc6b050-2691-48e1-be0d-f0424648adcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train[:,2:], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f1216f-0531-4af3-a5b7-e2899231117d",
   "metadata": {},
   "source": [
    "#### We can visualise our model using the following code - don't worry too much about the code. Just know that it first sets up the plot area, then colours the plot according to the mode estimated, then plots the training data and in a colour corresponding to the species according to a legend.\n",
    "\n",
    "#### The code below produces a warning about colours which is to boring to concern us. Don't worry about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0a6a02-2bb4-4a36-a19d-ba3e28cd7c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_neighbors = 1\n",
    "x_min,x_max = X_train[:,2].min() - 1, X_train[:,2].max()+ 1\n",
    "y_min,y_max = X_train[:,3].min() - 1, X_train[:,3].max()+ 1\n",
    "h=0.02\n",
    "xx,yy = np.meshgrid(np.arange(x_min,x_max,h),np.arange(y_min,y_max,h))\n",
    "Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "cmap_bold = ListedColormap(['darkorange', 'c', 'darkblue'])\n",
    "cmap_light=ListedColormap(['orange', 'cyan', 'cornflowerblue'])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.pcolormesh(xx, yy, Z, cmap=cmap_light, shading='gouraud')\n",
    "for target in iris_dataset.target_names:\n",
    "    index=np.where(iris_dataset.target_names==target)[0][0]\n",
    "    ax1.scatter(X_train[:,2][y_train==index],X_train[:,3][y_train==index],\n",
    "                cmap=cmap_bold,edgecolor='k', s=20, label=target)\n",
    "ax1.set_xlim(x_min,x_max)\n",
    "ax1.set_ylim(y_min,y_max)\n",
    "ax1.legend()\n",
    "ax1.set_xlabel(\"petal length (cm)\")\n",
    "ax1.set_ylabel(\"petal width (cm)\")\n",
    "ax1.set_title(\"3-Class classification (k = %i, weights = '%s')\"\n",
    "              % (n_neighbors, 'uniform'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c034e46e-1621-4652-8a5a-658abebd27ba",
   "metadata": {},
   "source": [
    "#### Have a look at your \"model\" and think about what this means for making predictions in the test set.\n",
    "\n",
    "### Questions\n",
    ">#### 6. What combinations of petal length and petal width are likely to be difficult to predict in the test set based on the figure?\n",
    ">#### 7. It is impossible to say for sure without extra analyses, but from the figure, do you think we've overfit or underfit the model to the data?\n",
    "\n",
    "#### The next step is to predict the value for a new flower. Imagine you found an Iris and took measurements of 4, 3.5, 1.2, and 0.5 cm for sepal length, sepal width, petal length and petal width respectively? What species does our model propose this flower belongs to? Remember, you don't actually know for sure in this case, though it's pretty clear cut here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e766b5-1a78-47d1-9c24-6bbbbfb13df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data=np.array([[4,3.5,1.2,0.5]])\n",
    "prediction = knn.predict(new_data[:,2:])\n",
    "print(\"Prediction: {}\".format(prediction))\n",
    "print(\"Predicted target name: {}\".format(iris_dataset['target_names'][prediction]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88304cb1-fe5d-4b2e-9cfa-b4f74f1d1bdf",
   "metadata": {},
   "source": [
    "#### Now is the moment of truth. Does our model predict the species well on an independent dataset (our test set)?\n",
    "\n",
    "#### To ask this question, we throw the X values (petal length and width) of the test set at our model and return the predictions. After this, you can print the true values of the species (0 = setosa, 1 = versicolor, 2 = virginica) and the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4be191a-5b65-42a0-a278-f1efceae2370",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test[:,2:])\n",
    "print(\"Test set predictions:\\n {}\".format(y_pred))\n",
    "print(\"Test set true values:\\n {}\".format(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41392610-4a11-44cc-8356-14acd4a13d5a",
   "metadata": {},
   "source": [
    "### Questions\n",
    ">#### 8. What is the true species of the flower which was incorrectly asigned a species by our model?\n",
    ">#### 9. What is the predicted species of the flower which was incorrectly assigned a species by our model?\n",
    "\n",
    "#### We can also ask how accurate the model is - in this case simply as a measure of the proportion of corrections that were correct of the total number of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca10f54-1811-4c21-a238-540e4ee7d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test set score: {:.2f}\".format(knn.score(X_test[:,2:], y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfb8776-2a9f-4689-8860-70e87a4cdc8d",
   "metadata": {},
   "source": [
    "#### We can plot the values for the test set on the same axes that we plotted the training points.\n",
    "\n",
    "#### As before, ignore the warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9d1cad-c54b-4191-8788-24a15481a1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min,x_max = X_train[:,2].min() - 1, X_train[:,2].max()+ 1\n",
    "y_min,y_max = X_train[:,3].min() - 1, X_train[:,3].max()+ 1\n",
    "h=0.02\n",
    "xx,yy = np.meshgrid(np.arange(x_min,x_max,h),np.arange(y_min,y_max,h))\n",
    "Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "cmap_bold = ListedColormap(['darkorange', 'c', 'darkblue'])\n",
    "cmap_light=ListedColormap(['orange', 'cyan', 'cornflowerblue'])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.pcolormesh(xx, yy, Z, cmap=cmap_light, shading='gouraud')\n",
    "for target in iris_dataset.target_names:\n",
    "    index=np.where(iris_dataset.target_names==target)[0][0]\n",
    "    ax1.scatter(X_test[:,2][y_test==index],X_test[:,3][y_test==index],\n",
    "                cmap=cmap_bold,edgecolor='k', s=20, label=target)\n",
    "ax1.set_xlim(x_min,x_max)\n",
    "ax1.set_ylim(y_min,y_max)\n",
    "ax1.legend()\n",
    "ax1.set_xlabel(\"petal length (cm)\")\n",
    "ax1.set_ylabel(\"petal width (cm)\")\n",
    "ax1.set_title(\"3-Class classification (k = %i, weights = '%s')\"\n",
    "              % (n_neighbors, 'uniform'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bdc688-7da6-43cf-8724-95d0ef630097",
   "metadata": {},
   "source": [
    "#### Ask yourself how the model performs. Were you right about the range in which prediction would be more difficult?\n",
    "\n",
    "### Questions\n",
    ">#### 10. Can you think of any downsides of the K nearest neighbours algorithm for this dataset?\n",
    ">#### 11. In a hypothetical scenario, you are given a load more data and your accuracy reduces to .9. Upon investigation you find that your model is overfit. This means that the model is inferring patterns that are true only of the training set, meaining they are not generalisable. How might you adapt your strategy to reduce overfitting but still using K nearest neighbours?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d405a0d0-427c-4026-9c48-4b9f1dcaee43",
   "metadata": {},
   "source": [
    "### Random forests\n",
    "\n",
    "#### Assuming no dreadful miscalculation of timings on the part of your instructor, you will have heard about [Random Forests](https://towardsdatascience.com/random-forest-3a55c3aca46d) in the lecture part of this taster session. I hope you were paying attention.\n",
    "\n",
    "#### Just in case you weren't, Random Forest is a machine learning algorithm that asks questions of our data using decision trees. The model is built by slowly splitting the dataset into purer classes (i.e. moving towards all setosa or versicolor etc.) according to the X values. A tree might split the data into those with a petal length over 3cm and those with petal length under 3cm. Those flowers with length over 3cm might then be split into those with petal width over 1.5cm and those with petla width under 1.5cm. This happens sequentially until the nodes of the tree are at some desired purity level (in this case complete purity) or the tree reaches a maximum depth (in this case 8). The random forest generates a given number of trees to make its predictions, here 100.\n",
    "\n",
    "#### Unlike K nearest neighbours above, we will use all 4 features to create our model here. In principle, Random Forests should rely on the most informative features without us specifying them so there isn't much need to worry about which features will be most informative, though too many completely useless features will reduce the efficacy of the model.\n",
    "\n",
    "#### As we've seen, in sklearn, you set up the model first then fit it to your data, which is done below. Have a look at the parameters and think about how the analysis might change under different hyperparameters. To read what each of these parameters does, you can look at the [sklearn Random Forest classifier documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205c7095-befb-4043-af72-1179497b9e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators = 100,\n",
    "                                       max_depth = 8,\n",
    "                                       max_features='sqrt',\n",
    "                                       min_samples_split=2,\n",
    "                                       n_jobs=1,\n",
    "                                       random_state=0)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95c8f0b-3b8e-4407-9001-ec2dcbc2bc9e",
   "metadata": {},
   "source": [
    "#### To give you an idea of what the model actually looks like, here is some code that plots the first of the trees in your forest, which should all look identical because you've been given the same starting seed. In each box you are given:\n",
    ">#### a) The decision being made (how the dataset is being split). This is missing in terminal nodes.\n",
    ">#### b) The [GINI importance](https://sam-black.medium.com/calculating-a-features-importance-with-xgboost-and-gini-impurity-3beb4e003b80) of that node. Don't worry too much about GINI unless you are especially interested. For now, you can think of it as the efficacy with which that node splits the tree into purer samples\n",
    ">#### c) The number of samples (flowers) that have taken the path leading to that node\n",
    ">#### d) The value - number of samples of each species that have taken the path leading to that node, formatted as [N_setosa, N_versicolor, N_virginica]\n",
    ">#### e) the class that would be predicted if a new flower took that path through the tree.\n",
    "\n",
    "#### NOTE: when a flower satisfies the condition set out in the decision in a box it always passes to left-hand box below and flowers that do not satisfy the condition follow the branch on the right-hand side!\n",
    "\n",
    "#### In my view, the tree displayed below will confirm the _Iris setosa_ is the easiest species to discriminate but also shows how random forests can find complex patterns of features that lead to a distinction between _Iris versicolor_ and _Iris virginica_.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a697414-e86c-44a2-b187-883665c44142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "fn=iris_dataset['feature_names']\n",
    "cn=iris_dataset['target_names']\n",
    "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=800)\n",
    "tree.plot_tree(model.estimators_[0],\n",
    "               feature_names = fn, \n",
    "               class_names=cn,\n",
    "               filled = True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa867c3-d8ce-4320-8053-993e83f51c89",
   "metadata": {},
   "source": [
    "### Questions\n",
    ">#### 12. How many _Iris setosa_ plants in the training set have a petal width > 0.75cm?\n",
    ">#### 13. Which species would a flower with petal width 2.0cm, petal length 4.1cm, sepal length 6.6cm, and sepal width 2.4cm be predicted to be by the tree displayed here?\n",
    ">#### 14. What is the route taken through this tree by the majority of _Iris virginica_ plants?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7a8189-b1d9-443d-b3b0-2ad5e193a86d",
   "metadata": {},
   "source": [
    "#### Now we predict the species for our test set and compare to the true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd36926f-12f9-48b4-9a9e-f368a3d73ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(X_test)\n",
    "print(\"Test set predictions:\\n {}\".format(y_pred_test))\n",
    "print(\"Test set true values:\\n {}\".format(y_test))\n",
    "print(\"Test set score: {:.2f}\".format(model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcb4f04-5661-49b8-8468-e1bd797a993f",
   "metadata": {},
   "source": [
    "#### So, with all that extra fuss about trees etc., our result is exactly the same. The same flower is predicted to be the same, incorrect species with all the rest being correct. Clearly, in this case, the extra complexity of the random forest, at least in how it was implemented here, has not improved prediction, though with more data, who knows what would happen?\n",
    "\n",
    "#### There is still an added benefit of the Random Forest algorithm over K nearest neighbours. Remember when I said you don't need to worry too much about GINI? Well the commands below will print the values of GINI for each of the 4 different features. Again, we don't need to worry too much about the specifics of GINI, but you can know that it gives you an idea of the relative importance of each of the features in building the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5991dc9-df4b-4f62-b5dd-2c9d0a2f3098",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    print(iris_dataset['feature_names'][i])\n",
    "    print(model.feature_importances_[i].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe4fda2-31fc-47ff-8bca-56ead38008ba",
   "metadata": {},
   "source": [
    "### Questions\n",
    ">#### 15. Order the variables in most important to least important. Compare with the scatter matrix. Does this fit your expectations?\n",
    "\n",
    "#### That's the base practical done. Well done. If you are finished but your appetite for machine learning has not yet been satiated, you can play about with the code to your heart's content. Here are some suggestions.\n",
    ">#### Change the parameters of the K nearest neigbours algorithm and rerun, comparing results with the basic ones.\n",
    ">#### Change the parameters of the Random Forest part of the practical and see how results change. You might find it intersting to see how results change with only 1 tree of max depth 2 or something. This wouldn't be a good analysis but could show how much is acheived by just one feature\n",
    ">#### Implement your own sklearn algorthm on the data - perhaps a neural network. This might be very difficult - I've not done it myself.\n",
    "\n",
    "#### If you need any help with the controls of the jupyter notebook, let the instructor(s) know."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
